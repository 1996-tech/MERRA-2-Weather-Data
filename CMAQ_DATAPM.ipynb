{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a857fe99-6ee6-4266-bd68-549b30887eff",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\priom\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key]\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[key]\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('C:\\\\Users\\\\priom\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '25f57d33-d349-4663-9927-37f57287f98d']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Open the NetCDF file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Extract the variables\u001b[39;00m\n\u001b[0;32m      9\u001b[0m lat \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\api.py:566\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m decoders \u001b[38;5;241m=\u001b[39m _resolve_decoders_kwargs(\n\u001b[0;32m    555\u001b[0m     decode_cf,\n\u001b[0;32m    556\u001b[0m     open_backend_dataset_parameters\u001b[38;5;241m=\u001b[39mbackend\u001b[38;5;241m.\u001b[39mopen_dataset_parameters,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    562\u001b[0m     decode_coords\u001b[38;5;241m=\u001b[39mdecode_coords,\n\u001b[0;32m    563\u001b[0m )\n\u001b[0;32m    565\u001b[0m overwrite_encoded_chunks \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moverwrite_encoded_chunks\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 566\u001b[0m backend_ds \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mopen_dataset(\n\u001b[0;32m    567\u001b[0m     filename_or_obj,\n\u001b[0;32m    568\u001b[0m     drop_variables\u001b[38;5;241m=\u001b[39mdrop_variables,\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecoders,\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    572\u001b[0m ds \u001b[38;5;241m=\u001b[39m _dataset_from_backend_dataset(\n\u001b[0;32m    573\u001b[0m     backend_ds,\n\u001b[0;32m    574\u001b[0m     filename_or_obj,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    585\u001b[0m )\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:590\u001b[0m, in \u001b[0;36mNetCDF4BackendEntrypoint.open_dataset\u001b[1;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_dataset\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]  # allow LSP violation, not supporting **kwargs\u001b[39;00m\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    571\u001b[0m     filename_or_obj: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m os\u001b[38;5;241m.\u001b[39mPathLike[Any] \u001b[38;5;241m|\u001b[39m BufferedIOBase \u001b[38;5;241m|\u001b[39m AbstractDataStore,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m     autoclose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    588\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dataset:\n\u001b[0;32m    589\u001b[0m     filename_or_obj \u001b[38;5;241m=\u001b[39m _normalize_path(filename_or_obj)\n\u001b[1;32m--> 590\u001b[0m     store \u001b[38;5;241m=\u001b[39m NetCDF4DataStore\u001b[38;5;241m.\u001b[39mopen(\n\u001b[0;32m    591\u001b[0m         filename_or_obj,\n\u001b[0;32m    592\u001b[0m         mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    593\u001b[0m         \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[0;32m    594\u001b[0m         group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[0;32m    595\u001b[0m         clobber\u001b[38;5;241m=\u001b[39mclobber,\n\u001b[0;32m    596\u001b[0m         diskless\u001b[38;5;241m=\u001b[39mdiskless,\n\u001b[0;32m    597\u001b[0m         persist\u001b[38;5;241m=\u001b[39mpersist,\n\u001b[0;32m    598\u001b[0m         lock\u001b[38;5;241m=\u001b[39mlock,\n\u001b[0;32m    599\u001b[0m         autoclose\u001b[38;5;241m=\u001b[39mautoclose,\n\u001b[0;32m    600\u001b[0m     )\n\u001b[0;32m    602\u001b[0m     store_entrypoint \u001b[38;5;241m=\u001b[39m StoreBackendEntrypoint()\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m close_on_error(store):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[1;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[0;32m    385\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    386\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[0;32m    387\u001b[0m )\n\u001b[0;32m    388\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[0;32m    389\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[0;32m    390\u001b[0m )\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(manager, group\u001b[38;5;241m=\u001b[39mgroup, mode\u001b[38;5;241m=\u001b[39mmode, lock\u001b[38;5;241m=\u001b[39mlock, autoclose\u001b[38;5;241m=\u001b[39mautoclose)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:338\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[1;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[0;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\netCDF4_.py:394\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 394\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m    395\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\backends\\file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[1;34m(self, needs_lock)\u001b[0m\n\u001b[0;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[1;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2521\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\netCDF4\\\\_netCDF4.pyx:2158\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\priom\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\Downloads\\\\M2T1NXAER_5.12.4-20250117_084759\\\\HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the NetCDF file\n",
    "ds = xr.open_dataset('Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Extract the variables\n",
    "lat = ds['x'].values\n",
    "lon = ds['y'].values\n",
    "time = ds['time'].values\n",
    "pm25 = ds['PM25_AVG'].values\n",
    "\n",
    "# Create meshgrid of latitude and longitude\n",
    "lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "# Flatten the spatial coordinates\n",
    "lat_flat = lat_grid.flatten()\n",
    "lon_flat = lon_grid.flatten()\n",
    "\n",
    "# Initialize list to store DataFrames for each timestamp\n",
    "dfs = []\n",
    "\n",
    "# Process each timestamp\n",
    "for t in range(len(time)):\n",
    "    # Extract PM2.5 data for this timestamp and flatten\n",
    "    pm25_slice = pm25[t].flatten()\n",
    "    \n",
    "    # Create DataFrame for this timestamp\n",
    "    df_t = pd.DataFrame({\n",
    "        'Latitude': lat_flat,\n",
    "        'Longitude': lon_flat,\n",
    "        'PM2.5': pm25_slice\n",
    "    })\n",
    "    \n",
    "    # Remove any rows with missing PM2.5 values\n",
    "    df_t = df_t.dropna()\n",
    "    \n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps into one DataFrame\n",
    "# Each timestamp will be a new column\n",
    "final_df = pd.concat([df.set_index(['Latitude', 'Longitude'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = pd.to_datetime(time)\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"Data has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fac3fbcb-87e7-4664-9047-62952e8b3824",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\dataset.py:1393\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1392\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1393\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[name]\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'x'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Rest of the code remains the same as before\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m lat \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     10\u001b[0m lon \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     11\u001b[0m time \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\dataset.py:1484\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1482\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkey)\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39mhashable(key):\n\u001b[1;32m-> 1484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_dataarray(key)\n\u001b[0;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m utils\u001b[38;5;241m.\u001b[39miterable_of_hashable(key):\n\u001b[0;32m   1486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copy_listed(key)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\dataset.py:1395\u001b[0m, in \u001b[0;36mDataset._construct_dataarray\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1393\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables[name]\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m-> 1395\u001b[0m     _, name, variable \u001b[38;5;241m=\u001b[39m _get_virtual_variable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m   1397\u001b[0m needed_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(variable\u001b[38;5;241m.\u001b[39mdims)\n\u001b[0;32m   1399\u001b[0m coords: \u001b[38;5;28mdict\u001b[39m[Hashable, Variable] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\xarray\\core\\dataset.py:196\u001b[0m, in \u001b[0;36m_get_virtual_variable\u001b[1;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[0;32m    194\u001b[0m split_key \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(split_key) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[0;32m    198\u001b[0m ref_name, var_name \u001b[38;5;241m=\u001b[39m split_key\n\u001b[0;32m    199\u001b[0m ref_var \u001b[38;5;241m=\u001b[39m variables[ref_name]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Use the correct path - adjust this to match your actual file location\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Rest of the code remains the same as before\n",
    "lat = ds['x'].values\n",
    "lon = ds['y'].values\n",
    "time = ds['time'].values\n",
    "pm25 = ds['PM25_AVG'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc904108-98fa-4e63-a1e1-fc5e9d558993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "xarray.Dataset {\n",
      "dimensions:\n",
      "\tTSTEP = 366 ;\n",
      "\tVAR = 14 ;\n",
      "\tDATE-TIME = 2 ;\n",
      "\tLAY = 1 ;\n",
      "\tROW = 299 ;\n",
      "\tCOL = 459 ;\n",
      "\n",
      "variables:\n",
      "\tint32 TFLAG(TSTEP, VAR, DATE-TIME) ;\n",
      "\t\tTFLAG:units = <YYYYDDD,HHMMSS> ;\n",
      "\t\tTFLAG:long_name = TFLAG            ;\n",
      "\t\tTFLAG:var_desc = Timestep-valid flags:  (1) YYYYDDD or (2) HHMMSS                                 ;\n",
      "\tfloat32 O3_MDA8(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tO3_MDA8:long_name = O3_MDA8          ;\n",
      "\t\tO3_MDA8:units = ppbV             ;\n",
      "\t\tO3_MDA8:var_desc = Max-8-hour                                                                       ;\n",
      "\tfloat32 O3_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tO3_AVG:long_name = O3_AVG           ;\n",
      "\t\tO3_AVG:units = ppbV             ;\n",
      "\t\tO3_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 CO_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tCO_AVG:long_name = CO_AVG           ;\n",
      "\t\tCO_AVG:units = ppbV             ;\n",
      "\t\tCO_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 NO_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tNO_AVG:long_name = NO_AVG           ;\n",
      "\t\tNO_AVG:units = ppbV             ;\n",
      "\t\tNO_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 NO2_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tNO2_AVG:long_name = NO2_AVG          ;\n",
      "\t\tNO2_AVG:units = ppbV             ;\n",
      "\t\tNO2_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 SO2_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tSO2_AVG:long_name = SO2_AVG          ;\n",
      "\t\tSO2_AVG:units = ppbV             ;\n",
      "\t\tSO2_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 CH2O_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tCH2O_AVG:long_name = CH2O_AVG         ;\n",
      "\t\tCH2O_AVG:units = ppbV             ;\n",
      "\t\tCH2O_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM10_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM10_AVG:long_name = PM10_AVG         ;\n",
      "\t\tPM10_AVG:units = ug/m3            ;\n",
      "\t\tPM10_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_AVG:long_name = PM25_AVG         ;\n",
      "\t\tPM25_AVG:units = ug/m3            ;\n",
      "\t\tPM25_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_SO4_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_SO4_AVG:long_name = PM25_SO4_AVG     ;\n",
      "\t\tPM25_SO4_AVG:units = ug/m3            ;\n",
      "\t\tPM25_SO4_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_NO3_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_NO3_AVG:long_name = PM25_NO3_AVG     ;\n",
      "\t\tPM25_NO3_AVG:units = ug/m3            ;\n",
      "\t\tPM25_NO3_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_NH4_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_NH4_AVG:long_name = PM25_NH4_AVG     ;\n",
      "\t\tPM25_NH4_AVG:units = ug/m3            ;\n",
      "\t\tPM25_NH4_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_OC_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_OC_AVG:long_name = PM25_OC_AVG      ;\n",
      "\t\tPM25_OC_AVG:units = ug/m3            ;\n",
      "\t\tPM25_OC_AVG:var_desc = Daily-average                                                                    ;\n",
      "\tfloat32 PM25_EC_AVG(TSTEP, LAY, ROW, COL) ;\n",
      "\t\tPM25_EC_AVG:long_name = PM25_EC_AVG      ;\n",
      "\t\tPM25_EC_AVG:units = ug/m3            ;\n",
      "\t\tPM25_EC_AVG:var_desc = Daily-average                                                                    ;\n",
      "\n",
      "// global attributes:\n",
      "\t:IOAPI_VERSION = $Id: @(#) ioapi library version 3.1 $                                            ;\n",
      "\t:EXEC_ID = ????????????????                                                                 ;\n",
      "\t:FTYPE = 1 ;\n",
      "\t:CDATE = 2021211 ;\n",
      "\t:CTIME = 215738 ;\n",
      "\t:WDATE = 2021211 ;\n",
      "\t:WTIME = 215738 ;\n",
      "\t:SDATE = 2016001 ;\n",
      "\t:STIME = 0 ;\n",
      "\t:TSTEP = 240000 ;\n",
      "\t:NTHIK = 1 ;\n",
      "\t:NCOLS = 459 ;\n",
      "\t:NROWS = 299 ;\n",
      "\t:NLAYS = 1 ;\n",
      "\t:NVARS = 14 ;\n",
      "\t:GDTYP = 2 ;\n",
      "\t:P_ALP = 33.0 ;\n",
      "\t:P_BET = 45.0 ;\n",
      "\t:P_GAM = -97.0 ;\n",
      "\t:XCENT = -97.0 ;\n",
      "\t:YCENT = 40.0 ;\n",
      "\t:XORIG = -2556000.0 ;\n",
      "\t:YORIG = -1728000.0 ;\n",
      "\t:XCELL = 12000.0 ;\n",
      "\t:YCELL = 12000.0 ;\n",
      "\t:VGTYP = -9999 ;\n",
      "\t:VGTOP = 5000.0 ;\n",
      "\t:VGLVLS = [1.     0.9975] ;\n",
      "\t:GDNAM = 12US1            ;\n",
      "\t:UPNAM = hr2day           ;\n",
      "\t:VAR-LIST = O3_MDA8         O3_AVG          CO_AVG          NO_AVG          NO2_AVG         SO2_AVG         CH2O_AVG        PM10_AVG        PM25_AVG        PM25_SO4_AVG    PM25_NO3_AVG    PM25_NH4_AVG    PM25_OC_AVG     PM25_EC_AVG      ;\n",
      "\t:FILEDESC = Concentration file output                                                       Averaged over the synchronization time steps                                    Timestamp represents beginning computed date/time                               Layer mapping (CGRID to AGRID):                                                 Layer  1 to  1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   ;\n",
      "\t:HISTORY =  ;\n",
      "}None\n",
      "\n",
      "Available variables:\n",
      "TFLAG\n",
      "O3_MDA8\n",
      "O3_AVG\n",
      "CO_AVG\n",
      "NO_AVG\n",
      "NO2_AVG\n",
      "SO2_AVG\n",
      "CH2O_AVG\n",
      "PM10_AVG\n",
      "PM25_AVG\n",
      "PM25_SO4_AVG\n",
      "PM25_NO3_AVG\n",
      "PM25_NH4_AVG\n",
      "PM25_OC_AVG\n",
      "PM25_EC_AVG\n",
      "\n",
      "Dimensions:\n",
      "Frozen({'TSTEP': 366, 'VAR': 14, 'DATE-TIME': 2, 'LAY': 1, 'ROW': 299, 'COL': 459})\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Print information about the dataset\n",
    "print(\"Dataset info:\")\n",
    "print(ds.info())\n",
    "\n",
    "# Print all variable names\n",
    "print(\"\\nAvailable variables:\")\n",
    "for var_name in ds.variables:\n",
    "    print(var_name)\n",
    "\n",
    "# Print all dimension names\n",
    "print(\"\\nDimensions:\")\n",
    "print(ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f745b1fc-ce30-4be5-b133-c7b784cd97ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "Unknown datetime string format, unable to parse: <xar-01-01, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m time_flags \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTFLAG\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get the date part for the first variable\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Convert YYYYDDD to datetime\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime([\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(flag)[:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-01-01\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m time_flags]) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m     29\u001b[0m         pd\u001b[38;5;241m.\u001b[39mto_timedelta([\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mstr\u001b[39m(flag)[\u001b[38;5;241m4\u001b[39m:]) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m flag \u001b[38;5;129;01min\u001b[39;00m time_flags], unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Create DataFrame for each timestep\u001b[39;00m\n\u001b[0;32m     32\u001b[0m dfs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1086\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_maybe_cache\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;66;03m# \"Union[float, str, datetime, List[Any], Tuple[Any, ...], ExtensionArray,\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m     \u001b[38;5;66;03m# ndarray[Any, Any], Series]\"; expected \"Union[List[Any], Tuple[Any, ...],\u001b[39;00m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# Union[Union[ExtensionArray, ndarray[Any, Any]], Index, Series], Series]\"\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     argc \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1084\u001b[0m         Union[\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, ExtensionArray, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries\u001b[39m\u001b[38;5;124m\"\u001b[39m, Index], arg\n\u001b[0;32m   1085\u001b[0m     )\n\u001b[1;32m-> 1086\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(argc, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutOfBoundsDatetime:\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;66;03m# caching attempts to create a DatetimeIndex, which may raise\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;66;03m# an OOB. If that's the desired behavior, then just reraise...\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:247\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[1;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[0;32m    245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m unique(arg)\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m--> 247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m# GH#45319\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m objects_to_datetime64(\n\u001b[0;32m    436\u001b[0m     arg,\n\u001b[0;32m    437\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m    438\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m    439\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m    440\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    441\u001b[0m     allow_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    442\u001b[0m )\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m tslib\u001b[38;5;241m.\u001b[39marray_to_datetime(\n\u001b[0;32m   2399\u001b[0m     data,\n\u001b[0;32m   2400\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   2401\u001b[0m     utc\u001b[38;5;241m=\u001b[39mutc,\n\u001b[0;32m   2402\u001b[0m     dayfirst\u001b[38;5;241m=\u001b[39mdayfirst,\n\u001b[0;32m   2403\u001b[0m     yearfirst\u001b[38;5;241m=\u001b[39myearfirst,\n\u001b[0;32m   2404\u001b[0m     creso\u001b[38;5;241m=\u001b[39mabbrev_to_npy_unit(out_unit),\n\u001b[0;32m   2405\u001b[0m )\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:553\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:666\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: Unknown datetime string format, unable to parse: <xar-01-01, at position 0"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get grid parameters from global attributes\n",
    "xcell = ds.attrs['XCELL']  # grid cell size in x direction\n",
    "ycell = ds.attrs['YCELL']  # grid cell size in y direction\n",
    "xorig = ds.attrs['XORIG']  # x-coordinate of origin\n",
    "yorig = ds.attrs['YORIG']  # y-coordinate of origin\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = xorig + xcell * np.arange(ds.dims['COL'])\n",
    "y_coords = yorig + ycell * np.arange(ds.dims['ROW'])\n",
    "\n",
    "# Create latitude/longitude meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Get time information from TFLAG\n",
    "# TFLAG contains date information in YYYYDDD format\n",
    "time_flags = ds['TFLAG'][:, 0, 0]  # Get the date part for the first variable\n",
    "# Convert YYYYDDD to datetime\n",
    "dates = pd.to_datetime([f\"{str(flag)[:4]}-01-01\" for flag in time_flags]) + \\\n",
    "        pd.to_timedelta([int(str(flag)[4:]) - 1 for flag in time_flags], unit='D')\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "    # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "    pm25_slice = pm25_data[t, 0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_t = pd.DataFrame({\n",
    "        'X_Coord': xx.flatten(),\n",
    "        'Y_Coord': yy.flatten(),\n",
    "        'PM2.5': pm25_slice.flatten()\n",
    "    })\n",
    "    \n",
    "    # Remove any missing values\n",
    "    df_t = df_t.dropna()\n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['X_Coord', 'Y_Coord'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"Data has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24572ded-10df-47aa-abaf-18f6da176bb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "DateParseError",
     "evalue": "year 2016001 is out of range: 2016001",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mparsing.pyx:684\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: year 2016001 is out of range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDateParseError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m time_flags \u001b[38;5;241m=\u001b[39m ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTFLAG\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues  \u001b[38;5;66;03m# Get the date part for the first variable\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Create dates list (assuming SDATE from global attributes indicates start date)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m start_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;28mstr\u001b[39m(ds\u001b[38;5;241m.\u001b[39mattrs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSDATE\u001b[39m\u001b[38;5;124m'\u001b[39m]))  \u001b[38;5;66;03m# Should be 2016001\u001b[39;00m\n\u001b[0;32m     29\u001b[0m dates \u001b[38;5;241m=\u001b[39m [start_date \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(days\u001b[38;5;241m=\u001b[39mi) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(time_flags))]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Create DataFrame for each timestep\u001b[39;00m\n",
      "File \u001b[1;32mtimestamps.pyx:1865\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.timestamps.Timestamp.__new__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:364\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mconversion.pyx:641\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.conversion.convert_str_to_tsobject\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:336\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.parse_datetime_string\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsing.pyx:688\u001b[0m, in \u001b[0;36mpandas._libs.tslibs.parsing.dateutil_parse\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mDateParseError\u001b[0m: year 2016001 is out of range: 2016001"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get grid parameters from global attributes\n",
    "xcell = ds.attrs['XCELL']  # grid cell size in x direction\n",
    "ycell = ds.attrs['YCELL']  # grid cell size in y direction\n",
    "xorig = ds.attrs['XORIG']  # x-coordinate of origin\n",
    "yorig = ds.attrs['YORIG']  # y-coordinate of origin\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = xorig + xcell * np.arange(ds.dims['COL'])\n",
    "y_coords = yorig + ycell * np.arange(ds.dims['ROW'])\n",
    "\n",
    "# Create latitude/longitude meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Get time information from TFLAG\n",
    "time_flags = ds['TFLAG'][:, 0, 0].values  # Get the date part for the first variable\n",
    "\n",
    "# Create dates list (assuming SDATE from global attributes indicates start date)\n",
    "start_date = pd.Timestamp(str(ds.attrs['SDATE']))  # Should be 2016001\n",
    "dates = [start_date + pd.Timedelta(days=i) for i in range(len(time_flags))]\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "    # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "    pm25_slice = pm25_data[t, 0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_t = pd.DataFrame({\n",
    "        'X_Coord': xx.flatten(),\n",
    "        'Y_Coord': yy.flatten(),\n",
    "        'PM2.5': pm25_slice.flatten()\n",
    "    })\n",
    "    \n",
    "    # Remove any missing values\n",
    "    df_t = df_t.dropna()\n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['X_Coord', 'Y_Coord'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"Data has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ea13d5-e764-416b-a840-d488978fb187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of the first 5 rows and 5 columns of the data:\n",
      "                       2016-01-01  2016-01-02  2016-01-03  2016-01-04  \\\n",
      "X_Coord    Y_Coord                                                      \n",
      "-2556000.0 -1728000.0    1.413358    1.331079    1.376337    2.190387   \n",
      "-2544000.0 -1728000.0    1.398102    1.331326    1.389859    2.272398   \n",
      "-2532000.0 -1728000.0    1.372702    1.334618    1.404449    2.367060   \n",
      "-2520000.0 -1728000.0    1.354613    1.340229    1.406716    2.481329   \n",
      "-2508000.0 -1728000.0    1.335252    1.340366    1.415844    2.504131   \n",
      "\n",
      "                       2016-01-05  \n",
      "X_Coord    Y_Coord                 \n",
      "-2556000.0 -1728000.0    4.519111  \n",
      "-2544000.0 -1728000.0    4.704486  \n",
      "-2532000.0 -1728000.0    4.892936  \n",
      "-2520000.0 -1728000.0    4.997709  \n",
      "-2508000.0 -1728000.0    5.047138  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 137241 entries, (-2556000.0, -1728000.0) to (2940000.0, 1848000.0)\n",
      "Columns: 366 entries, 2016-01-01 to 2016-12-31\n",
      "dtypes: float32(366)\n",
      "memory usage: 192.2 MB\n",
      "None\n",
      "\n",
      "Basic statistics of PM2.5 values:\n",
      "          2016-01-01     2016-01-02     2016-01-03     2016-01-04  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        4.312621       4.062067       3.944738       3.907777   \n",
      "std         2.793922       2.653183       3.124055       2.714868   \n",
      "min         0.153220       0.010885       0.047520       0.057864   \n",
      "25%         2.191694       2.117664       1.705271       1.979969   \n",
      "50%         3.540092       3.413729       3.068003       3.216337   \n",
      "75%         5.758524       5.316417       5.565784       5.320272   \n",
      "max        27.995226      84.846344     405.232391     100.022072   \n",
      "\n",
      "          2016-01-05     2016-01-06     2016-01-07     2016-01-08  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        3.910911       4.248538       4.357111       4.230324   \n",
      "std         3.261223       4.242861       5.111894       5.099010   \n",
      "min         0.029361       0.104252       0.077533       0.180936   \n",
      "25%         1.807677       1.257515       1.164368       1.241142   \n",
      "50%         2.745925       2.540087       2.428921       2.600950   \n",
      "75%         5.095850       5.968206       5.465321       5.207768   \n",
      "max        82.252068     155.619553      80.011597      77.812019   \n",
      "\n",
      "          2016-01-09     2016-01-10  ...     2016-12-22     2016-12-23  \\\n",
      "count  137241.000000  137241.000000  ...  137241.000000  137241.000000   \n",
      "mean        3.227022       2.698887  ...       4.922876       5.032027   \n",
      "std         2.908482       1.867137  ...       4.528701       4.357444   \n",
      "min         0.109260       0.216599  ...       0.075370       0.182282   \n",
      "25%         1.269616       1.353020  ...       1.995089       2.116553   \n",
      "50%         2.327599       2.252809  ...       3.190825       3.606589   \n",
      "75%         4.178020       3.455667  ...       6.153344       6.250715   \n",
      "max        51.525036      49.283619  ...      86.128601     191.674149   \n",
      "\n",
      "          2016-12-24     2016-12-25     2016-12-26     2016-12-27  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        4.220720       3.397760       2.888707       3.134814   \n",
      "std         3.397214       2.587084       2.201258       2.414049   \n",
      "min         0.193321       0.236369       0.315840       0.094113   \n",
      "25%         2.055615       1.897772       1.441095       1.325298   \n",
      "50%         3.261372       2.782009       2.231143       2.412103   \n",
      "75%         5.209162       4.038377       3.648257       4.304586   \n",
      "max        77.933144      60.902115      56.858459     109.303627   \n",
      "\n",
      "          2016-12-28     2016-12-29     2016-12-30     2016-12-31  \n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000  \n",
      "mean        3.539500       2.985887       2.919786       3.001024  \n",
      "std         2.879699       1.992146       1.855269       2.016702  \n",
      "min         0.182064       0.182215       0.122628       0.014291  \n",
      "25%         1.417034       1.652451       1.774788       1.618538  \n",
      "50%         2.767618       2.575255       2.556890       2.452135  \n",
      "75%         4.632062       3.768340       3.688083       4.016738  \n",
      "max        66.500488      41.362064      97.778175      42.974651  \n",
      "\n",
      "[8 rows x 366 columns]\n",
      "\n",
      "Data has been processed and saved to 'pm25_data.csv'\n",
      "Shape of final dataset: (137241, 366)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get grid parameters from global attributes\n",
    "xcell = ds.attrs['XCELL']  # grid cell size in x direction\n",
    "ycell = ds.attrs['YCELL']  # grid cell size in y direction\n",
    "xorig = ds.attrs['XORIG']  # x-coordinate of origin\n",
    "yorig = ds.attrs['YORIG']  # y-coordinate of origin\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = xorig + xcell * np.arange(ds.dims['COL'])\n",
    "y_coords = yorig + ycell * np.arange(ds.dims['ROW'])\n",
    "\n",
    "# Create latitude/longitude meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Parse SDATE (format: YYYYDDD)\n",
    "sdate_str = str(ds.attrs['SDATE'])\n",
    "year = int(sdate_str[:4])\n",
    "day_of_year = int(sdate_str[4:])\n",
    "start_date = pd.Timestamp(year, 1, 1) + pd.Timedelta(days=day_of_year-1)\n",
    "\n",
    "# Create dates list\n",
    "dates = [start_date + pd.Timedelta(days=i) for i in range(ds.dims['TSTEP'])]\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "   # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "   pm25_slice = pm25_data[t, 0]\n",
    "   \n",
    "   # Create DataFrame\n",
    "   df_t = pd.DataFrame({\n",
    "       'X_Coord': xx.flatten(),\n",
    "       'Y_Coord': yy.flatten(),\n",
    "       'PM2.5': pm25_slice.flatten()\n",
    "   })\n",
    "   \n",
    "   # Remove any missing values\n",
    "   df_t = df_t.dropna()\n",
    "   dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['X_Coord', 'Y_Coord'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nPreview of the first 5 rows and 5 columns of the data:\")\n",
    "print(final_df.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(final_df.info())\n",
    "\n",
    "print(\"\\nBasic statistics of PM2.5 values:\")\n",
    "print(final_df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"\\nData has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eabd1574-733e-498d-9b45-c3902d87bf64",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyproj'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyproj\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Open the file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyproj'"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get projection parameters from global attributes\n",
    "p_alp = ds.attrs['P_ALP']  # First projection parallel\n",
    "p_bet = ds.attrs['P_BET']  # Second projection parallel\n",
    "p_gam = ds.attrs['P_GAM']  # Central meridian\n",
    "xcent = ds.attrs['XCENT']  # Projection center longitude\n",
    "ycent = ds.attrs['YCENT']  # Projection center latitude\n",
    "\n",
    "# Create the projection transformer\n",
    "proj_str = f\"+proj=lcc +lat_1={p_alp} +lat_2={p_bet} +lat_0={ycent} +lon_0={xcent} +x_0=0 +y_0=0 +ellps=sphere +units=m +no_defs\"\n",
    "transformer = Transformer.from_crs(proj_str, \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = np.arange(ds.dims['COL']) * ds.attrs['XCELL'] + ds.attrs['XORIG']\n",
    "y_coords = np.arange(ds.dims['ROW']) * ds.attrs['YCELL'] + ds.attrs['YORIG']\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Transform coordinates to lat/lon\n",
    "lons, lats = transformer.transform(xx, yy)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Parse SDATE (format: YYYYDDD)\n",
    "sdate_str = str(ds.attrs['SDATE'])\n",
    "year = int(sdate_str[:4])\n",
    "day_of_year = int(sdate_str[4:])\n",
    "start_date = pd.Timestamp(year, 1, 1) + pd.Timedelta(days=day_of_year-1)\n",
    "\n",
    "# Create dates list\n",
    "dates = [start_date + pd.Timedelta(days=i) for i in range(ds.dims['TSTEP'])]\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "    # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "    pm25_slice = pm25_data[t, 0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_t = pd.DataFrame({\n",
    "        'Latitude': lats.flatten(),\n",
    "        'Longitude': lons.flatten(),\n",
    "        'PM2.5': pm25_slice.flatten()\n",
    "    })\n",
    "    \n",
    "    # Remove any missing values\n",
    "    df_t = df_t.dropna()\n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['Latitude', 'Longitude'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nPreview of the first 5 rows and 5 columns of the data:\")\n",
    "print(final_df.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(final_df.info())\n",
    "\n",
    "print(\"\\nBasic statistics of PM2.5 values:\")\n",
    "print(final_df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"\\nData has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66c22b4b-cdf9-4955-99d7-10951e8c8ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyproj\n",
      "  Downloading pyproj-3.7.0-cp312-cp312-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\priom\\anaconda3\\lib\\site-packages (from pyproj) (2024.12.14)\n",
      "Downloading pyproj-3.7.0-cp312-cp312-win_amd64.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 2.1/6.2 MB 6.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 2.4/6.2 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.9/6.2 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.1/6.2 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.1/6.2 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.4/6.2 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.9/6.2 MB 2.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 4.2/6.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 1.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.0/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.2/6.2 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.8/6.2 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.0/6.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pyproj\n",
      "Successfully installed pyproj-3.7.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyproj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f33b093-1388-40cf-acac-fc81583fdbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of the first 5 rows and 5 columns of the data:\n",
      "                       2016-01-01  2016-01-02  2016-01-03  2016-01-04  \\\n",
      "Latitude  Longitude                                                     \n",
      "21.560428 -121.060390    1.413358    1.331079    1.376337    2.190387   \n",
      "21.587541 -120.952601    1.398102    1.331326    1.389859    2.272398   \n",
      "21.614538 -120.844743    1.372702    1.334618    1.404449    2.367060   \n",
      "21.641420 -120.736817    1.354613    1.340229    1.406716    2.481329   \n",
      "21.668187 -120.628821    1.335252    1.340366    1.415844    2.504131   \n",
      "\n",
      "                       2016-01-05  \n",
      "Latitude  Longitude                \n",
      "21.560428 -121.060390    4.519111  \n",
      "21.587541 -120.952601    4.704486  \n",
      "21.614538 -120.844743    4.892936  \n",
      "21.641420 -120.736817    4.997709  \n",
      "21.668187 -120.628821    5.047138  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 137241 entries, (21.560427879385422, -121.06039038106123) to (50.33150254956958, -54.688006819308974)\n",
      "Columns: 366 entries, 2016-01-01 to 2016-12-31\n",
      "dtypes: float32(366)\n",
      "memory usage: 200.3 MB\n",
      "None\n",
      "\n",
      "Basic statistics of PM2.5 values:\n",
      "          2016-01-01     2016-01-02     2016-01-03     2016-01-04  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        4.312621       4.062067       3.944738       3.907777   \n",
      "std         2.793922       2.653183       3.124055       2.714868   \n",
      "min         0.153220       0.010885       0.047520       0.057864   \n",
      "25%         2.191694       2.117664       1.705271       1.979969   \n",
      "50%         3.540092       3.413729       3.068003       3.216337   \n",
      "75%         5.758524       5.316417       5.565784       5.320272   \n",
      "max        27.995226      84.846344     405.232391     100.022072   \n",
      "\n",
      "          2016-01-05     2016-01-06     2016-01-07     2016-01-08  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        3.910911       4.248538       4.357111       4.230324   \n",
      "std         3.261223       4.242861       5.111894       5.099010   \n",
      "min         0.029361       0.104252       0.077533       0.180936   \n",
      "25%         1.807677       1.257515       1.164368       1.241142   \n",
      "50%         2.745925       2.540087       2.428921       2.600950   \n",
      "75%         5.095850       5.968206       5.465321       5.207768   \n",
      "max        82.252068     155.619553      80.011597      77.812019   \n",
      "\n",
      "          2016-01-09     2016-01-10  ...     2016-12-22     2016-12-23  \\\n",
      "count  137241.000000  137241.000000  ...  137241.000000  137241.000000   \n",
      "mean        3.227022       2.698887  ...       4.922876       5.032027   \n",
      "std         2.908482       1.867137  ...       4.528701       4.357444   \n",
      "min         0.109260       0.216599  ...       0.075370       0.182282   \n",
      "25%         1.269616       1.353020  ...       1.995089       2.116553   \n",
      "50%         2.327599       2.252809  ...       3.190825       3.606589   \n",
      "75%         4.178020       3.455667  ...       6.153344       6.250715   \n",
      "max        51.525036      49.283619  ...      86.128601     191.674149   \n",
      "\n",
      "          2016-12-24     2016-12-25     2016-12-26     2016-12-27  \\\n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000   \n",
      "mean        4.220720       3.397760       2.888707       3.134814   \n",
      "std         3.397214       2.587084       2.201258       2.414049   \n",
      "min         0.193321       0.236369       0.315840       0.094113   \n",
      "25%         2.055615       1.897772       1.441095       1.325298   \n",
      "50%         3.261372       2.782009       2.231143       2.412103   \n",
      "75%         5.209162       4.038377       3.648257       4.304586   \n",
      "max        77.933144      60.902115      56.858459     109.303627   \n",
      "\n",
      "          2016-12-28     2016-12-29     2016-12-30     2016-12-31  \n",
      "count  137241.000000  137241.000000  137241.000000  137241.000000  \n",
      "mean        3.539500       2.985887       2.919786       3.001024  \n",
      "std         2.879699       1.992146       1.855269       2.016702  \n",
      "min         0.182064       0.182215       0.122628       0.014291  \n",
      "25%         1.417034       1.652451       1.774788       1.618538  \n",
      "50%         2.767618       2.575255       2.556890       2.452135  \n",
      "75%         4.632062       3.768340       3.688083       4.016738  \n",
      "max        66.500488      41.362064      97.778175      42.974651  \n",
      "\n",
      "[8 rows x 366 columns]\n",
      "\n",
      "Data has been processed and saved to 'pm25_data.csv'\n",
      "Shape of final dataset: (137241, 366)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get projection parameters from global attributes\n",
    "p_alp = ds.attrs['P_ALP']  # First projection parallel\n",
    "p_bet = ds.attrs['P_BET']  # Second projection parallel\n",
    "p_gam = ds.attrs['P_GAM']  # Central meridian\n",
    "xcent = ds.attrs['XCENT']  # Projection center longitude\n",
    "ycent = ds.attrs['YCENT']  # Projection center latitude\n",
    "\n",
    "# Create the projection transformer\n",
    "proj_str = f\"+proj=lcc +lat_1={p_alp} +lat_2={p_bet} +lat_0={ycent} +lon_0={xcent} +x_0=0 +y_0=0 +ellps=sphere +units=m +no_defs\"\n",
    "transformer = Transformer.from_crs(proj_str, \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = np.arange(ds.dims['COL']) * ds.attrs['XCELL'] + ds.attrs['XORIG']\n",
    "y_coords = np.arange(ds.dims['ROW']) * ds.attrs['YCELL'] + ds.attrs['YORIG']\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Transform coordinates to lat/lon\n",
    "lons, lats = transformer.transform(xx, yy)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Parse SDATE (format: YYYYDDD)\n",
    "sdate_str = str(ds.attrs['SDATE'])\n",
    "year = int(sdate_str[:4])\n",
    "day_of_year = int(sdate_str[4:])\n",
    "start_date = pd.Timestamp(year, 1, 1) + pd.Timedelta(days=day_of_year-1)\n",
    "\n",
    "# Create dates list\n",
    "dates = [start_date + pd.Timedelta(days=i) for i in range(ds.dims['TSTEP'])]\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "    # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "    pm25_slice = pm25_data[t, 0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_t = pd.DataFrame({\n",
    "        'Latitude': lats.flatten(),\n",
    "        'Longitude': lons.flatten(),\n",
    "        'PM2.5': pm25_slice.flatten()\n",
    "    })\n",
    "    \n",
    "    # Remove any missing values\n",
    "    df_t = df_t.dropna()\n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['Latitude', 'Longitude'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nPreview of the first 5 rows and 5 columns of the data:\")\n",
    "print(final_df.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(final_df.info())\n",
    "\n",
    "print(\"\\nBasic statistics of PM2.5 values:\")\n",
    "print(final_df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"\\nData has been processed and saved to 'pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "103d251d-f8ac-4387-a951-f44724a36646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview of the first 5 rows and 5 columns of the data:\n",
      "                       2016-01-01  2016-01-02  2016-01-03  2016-01-04  \\\n",
      "Latitude  Longitude                                                     \n",
      "45.550694 -117.335418    2.079100    3.057056    2.835236    2.894924   \n",
      "45.574528 -117.185260    1.769747    2.589481    2.957903    2.991938   \n",
      "45.598188 -117.034990    2.255016    2.373785    3.058101    3.152895   \n",
      "45.558569 -117.970070    6.242252    3.597657    4.047945    4.324589   \n",
      "45.583136 -117.820134    6.572935    3.742129    3.636909    3.776148   \n",
      "\n",
      "                       2016-01-05  \n",
      "Latitude  Longitude                \n",
      "45.550694 -117.335418    2.224461  \n",
      "45.574528 -117.185260    2.674171  \n",
      "45.598188 -117.034990    3.387901  \n",
      "45.558569 -117.970070    4.463864  \n",
      "45.583136 -117.820134    3.771707  \n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1618 entries, (45.55069406771397, -117.33541827668462) to (49.001797060257985, -124.61160298766463)\n",
      "Columns: 366 entries, 2016-01-01 to 2016-12-31\n",
      "dtypes: float32(366)\n",
      "memory usage: 2.4 MB\n",
      "None\n",
      "\n",
      "Basic statistics of PM2.5 values:\n",
      "        2016-01-01   2016-01-02   2016-01-03   2016-01-04   2016-01-05  \\\n",
      "count  1618.000000  1618.000000  1618.000000  1618.000000  1618.000000   \n",
      "mean      4.033484     4.099157     4.074337     4.187454     4.514345   \n",
      "std       3.397240     2.854738     1.809432     2.369134     2.941058   \n",
      "min       0.895191     1.316116     1.951414     0.573347     0.579143   \n",
      "25%       1.883548     2.408526     2.820034     2.434784     2.438251   \n",
      "50%       2.863934     3.219106     3.436179     3.802296     3.699051   \n",
      "75%       5.055659     4.975598     4.872952     5.526160     5.911521   \n",
      "max      27.550684    26.655874    13.307239    16.144888    22.022585   \n",
      "\n",
      "        2016-01-06   2016-01-07   2016-01-08   2016-01-09   2016-01-10  ...  \\\n",
      "count  1618.000000  1618.000000  1618.000000  1618.000000  1618.000000  ...   \n",
      "mean      4.443538     5.167553     5.153594     3.894562     3.202609  ...   \n",
      "std       3.642297     4.394030     4.250726     3.109857     2.619018  ...   \n",
      "min       0.515892     0.530019     0.332814     0.447215     0.437426  ...   \n",
      "25%       2.111856     2.249489     2.020181     1.885125     1.391506  ...   \n",
      "50%       3.440136     4.042860     3.998543     3.031854     2.521997  ...   \n",
      "75%       5.764593     6.454508     6.998147     4.889915     4.106510  ...   \n",
      "max      56.765949    35.044727    34.675838    28.137903    20.942648  ...   \n",
      "\n",
      "        2016-12-22   2016-12-23   2016-12-24   2016-12-25   2016-12-26  \\\n",
      "count  1618.000000  1618.000000  1618.000000  1618.000000  1618.000000   \n",
      "mean      3.609568     2.715733     3.861943     5.150050     3.603132   \n",
      "std       2.584131     1.874664     3.410675     4.249013     2.800216   \n",
      "min       1.047905     0.438471     0.520287     0.464663     0.369419   \n",
      "25%       2.050807     1.530022     1.887199     2.651314     1.427625   \n",
      "50%       2.782923     2.228195     2.939111     4.485369     2.885410   \n",
      "75%       4.105370     3.304441     4.577341     6.023442     4.860178   \n",
      "max      22.252352    13.261958    50.329437    45.257202    20.644922   \n",
      "\n",
      "        2016-12-27   2016-12-28   2016-12-29   2016-12-30   2016-12-31  \n",
      "count  1618.000000  1618.000000  1618.000000  1618.000000  1618.000000  \n",
      "mean      1.515816     2.102499     2.614062     2.384006     2.537717  \n",
      "std       0.735238     2.258892     1.884713     2.387491     2.338669  \n",
      "min       0.303846     0.601421     0.522511     0.305008     0.394222  \n",
      "25%       0.988748     1.128080     1.453550     0.882288     1.058400  \n",
      "50%       1.438720     1.756441     2.178916     1.420537     1.732356  \n",
      "75%       1.877091     2.382553     3.031665     3.139718     3.068752  \n",
      "max       7.079185    66.500488    24.064871    17.566078    19.806734  \n",
      "\n",
      "[8 rows x 366 columns]\n",
      "\n",
      "Data has been processed and saved to 'washington_pm25_data.csv'\n",
      "Shape of final dataset: (1618, 366)\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "\n",
    "# Open the file\n",
    "ds = xr.open_dataset('C:/Users/priom/Downloads/M2T1NXAER_5.12.4-20250117_084759/HR2DAY_LST_ACONC_EQUATES_v532_12US1_2016.nc')\n",
    "\n",
    "# Get projection parameters from global attributes\n",
    "p_alp = ds.attrs['P_ALP']  # First projection parallel\n",
    "p_bet = ds.attrs['P_BET']  # Second projection parallel\n",
    "p_gam = ds.attrs['P_GAM']  # Central meridian\n",
    "xcent = ds.attrs['XCENT']  # Projection center longitude\n",
    "ycent = ds.attrs['YCENT']  # Projection center latitude\n",
    "\n",
    "# Create the projection transformer\n",
    "proj_str = f\"+proj=lcc +lat_1={p_alp} +lat_2={p_bet} +lat_0={ycent} +lon_0={xcent} +x_0=0 +y_0=0 +ellps=sphere +units=m +no_defs\"\n",
    "transformer = Transformer.from_crs(proj_str, \"EPSG:4326\", always_xy=True)\n",
    "\n",
    "# Create coordinate arrays\n",
    "x_coords = np.arange(ds.dims['COL']) * ds.attrs['XCELL'] + ds.attrs['XORIG']\n",
    "y_coords = np.arange(ds.dims['ROW']) * ds.attrs['YCELL'] + ds.attrs['YORIG']\n",
    "\n",
    "# Create meshgrid\n",
    "xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "# Transform coordinates to lat/lon\n",
    "lons, lats = transformer.transform(xx, yy)\n",
    "\n",
    "# Washington state boundaries\n",
    "wa_lat_min = 45.543541\n",
    "wa_lat_max = 49.002494\n",
    "wa_lon_min = -124.848974\n",
    "wa_lon_max = -116.916071\n",
    "\n",
    "# Create mask for Washington state\n",
    "wa_mask = (lats >= wa_lat_min) & (lats <= wa_lat_max) & \\\n",
    "          (lons >= wa_lon_min) & (lons <= wa_lon_max)\n",
    "\n",
    "# Get PM2.5 data\n",
    "pm25_data = ds['PM25_AVG'].values\n",
    "\n",
    "# Parse SDATE (format: YYYYDDD)\n",
    "sdate_str = str(ds.attrs['SDATE'])\n",
    "year = int(sdate_str[:4])\n",
    "day_of_year = int(sdate_str[4:])\n",
    "start_date = pd.Timestamp(year, 1, 1) + pd.Timedelta(days=day_of_year-1)\n",
    "\n",
    "# Create dates list\n",
    "dates = [start_date + pd.Timedelta(days=i) for i in range(ds.dims['TSTEP'])]\n",
    "\n",
    "# Create DataFrame for each timestep\n",
    "dfs = []\n",
    "for t in range(len(dates)):\n",
    "    # Extract PM2.5 data for this timestamp (taking first layer)\n",
    "    pm25_slice = pm25_data[t, 0]\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_t = pd.DataFrame({\n",
    "        'Latitude': lats[wa_mask],\n",
    "        'Longitude': lons[wa_mask],\n",
    "        'PM2.5': pm25_slice[wa_mask]\n",
    "    })\n",
    "    \n",
    "    # Remove any missing values\n",
    "    df_t = df_t.dropna()\n",
    "    dfs.append(df_t)\n",
    "\n",
    "# Combine all timestamps\n",
    "final_df = pd.concat([df.set_index(['Latitude', 'Longitude'])['PM2.5'] for df in dfs], axis=1)\n",
    "final_df.columns = dates\n",
    "\n",
    "# Preview the data\n",
    "print(\"\\nPreview of the first 5 rows and 5 columns of the data:\")\n",
    "print(final_df.iloc[:5, :5])\n",
    "\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(final_df.info())\n",
    "\n",
    "print(\"\\nBasic statistics of PM2.5 values:\")\n",
    "print(final_df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "final_df.to_csv('washington_pm25_data.csv')\n",
    "\n",
    "# Close the dataset\n",
    "ds.close()\n",
    "\n",
    "print(\"\\nData has been processed and saved to 'washington_pm25_data.csv'\")\n",
    "print(f\"Shape of final dataset: {final_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7198f00-d677-44d2-9ddf-a58794c57889",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Removing the repetation of lat, long \n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def process_pm25_data(file_path):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Get unique coordinates (latitude, longitude pairs)\n",
    "    unique_coords = df[['Latitude', 'Longitude']].drop_duplicates().sort_values(['Latitude', 'Longitude'])\n",
    "    \n",
    "    # Get all unique dates\n",
    "    dates = sorted(df['Date'].unique())\n",
    "    \n",
    "    # Create a new dataframe with latitude and longitude as the first columns\n",
    "    result = pd.DataFrame(unique_coords)\n",
    "    \n",
    "    # Add columns for each date with corresponding PM2.5 values\n",
    "    for date in dates:\n",
    "        date_data = df[df['Date'] == date]\n",
    "        \n",
    "        # Create a mapping of coordinates to PM2.5 values for this date\n",
    "        pm25_values = {}\n",
    "        for _, row in date_data.iterrows():\n",
    "            coord_key = (row['Latitude'], row['Longitude'])\n",
    "            pm25_values[coord_key] = row['Daily Mean PM2.5 Concentration']\n",
    "        \n",
    "        # Add the PM2.5 values for this date as a new column\n",
    "        result[date] = result.apply(\n",
    "            lambda x: pm25_values.get((x['Latitude'], x['Longitude']), np.nan), \n",
    "            axis=1\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "file_path = 'PM2.5_WA_DM.csv'\n",
    "result_df = process_pm25_data(file_path)\n",
    "\n",
    "# Save to CSV\n",
    "result_df.to_csv('processed_pm25_data.csv', index=False)\n",
    "\n",
    "# Display first few rows and columns\n",
    "print(\"\\nFirst few rows and columns of the processed data:\")\n",
    "print(result_df.iloc[:5, :7])  # Show first 5 rows and 7 columns\n",
    "\n",
    "# Display shape of the resulting dataframe\n",
    "print(\"\\nShape of the processed dataframe:\", result_df.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
